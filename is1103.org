* Introduction                                                     :noexport:
** Definitions
Cyberethics - study of moral, legal and social issues involving cybertechnology.
Cybertechnology - wide range of computing and communication devices.
** 4 phases
*** 1950s and 1960s
1. Building of ENIAC, huge mainframe computers, unconnected
2. Can machines think? Should these be invented?
3. What does it mean to be human?
4. Privacy threats, govt surveillance
*** 1970s and 1980s
1. networked computers, facilitate communication of information
2. Intellectual property, personal privacy, computer crime
*** 1990-present
1. World Wide Web
2. Free speech, anonymity
3. Geographical boundaries, legal jurisdiction
*** present-near future
1. Biotech, RFID
2. increased use of autonomous systems
** Cyberethics as different kinds of ethics
| Type          | Disciplines                        | Issues                                                                                     |
|---------------+------------------------------------+--------------------------------------------------------------------------------------------|
| Professional  | CS/Engineering/Information Science | Prof. Responsibility                                                                       |
|               |                                    | System Reliability                                                                         |
|               |                                    | Codes of Conduct                                                                           |
| Philosophical | Philosophy/Law                     | Privacy and Anonymity                                                                      |
|               |                                    | Intellectual Property                                                                      |
|               |                                    | Free Speech                                                                                |
| Sociological  | Sociology/Behavioural Sciences     | Impact of cybertech on govt/financial/educational institutions and sociodemographic groups |
** Methodology
1. Identify a practice involving cybertech, or a controversial feature
   - Disclose hidden/opaque features
   - Assess descriptive components of ethical issues via sociological implications
   - Analyze normative elements, determine if guidelines/policies can resolve the issue
2. Analyze ethical issue by clarifying concepts and situating it in context
   - If a policy vacuum exists, go next substep, if not go to step 3
   - Clear up any conceptual muddles involving policy vacuum
3. Deliberate on ethical issue
   - Apply one or more ethical theories to the analysis
   - Justify the position you reach via sound logical analysis
* Morality
1. Directives that guide our conduct as individuals
2. Social policies framed at the macrolevel

Moral systems are evaluated against standards called /principles/.
Morality is:

- Public :: Rules are public; Everyone is obligated to partake in a moral system
- Informal :: Has no formal authoritative judges presiding over it
- Impartial :: Moral rules are ideally designed to apply equitably to all participants
- Rational :: The system is based on principles of logical reason
* Values
- Instrumental :: Provide external benefit (eg. computers etc)
- Intrinsic :: Valued for their own sake (eg. life, happiness)
* Ethical Theories
** Consequence-based (Utilitarianism) 
Some have argued that the primary goal of a moral system is to produce
desirable consequences or outcomes for its members. For these
ethicists, the consequences (i.e., the ends achieved) of actions and
policies provide the ultimate standard against which moral decisions
must be evaluated

*** Utilitarianism
#+BEGIN_QUOTE
An individual act (X) or a social policy (Y) is morally permissible if
the consequences that result from (X) or (Y) produce the greatest
amount of good for the greatest number of persons affected by the act
or policy.
#+END_QUOTE

 1. Social utility is superior to alternative criteria for evaluating
    moral systems.
 2. Social utility can be measured by the amount of happiness
    produced.

Assumes:
1. All people desire happiness.
2. Happiness is an intrinsic good that is desired for its own sake.

*Act Utilitarianism:*

#+BEGIN_QUOTE
An act, X, is morally permissible if the consequences produced by
doing X result in the greatest good for the greatest number of persons
affected by Act X.
#+END_QUOTE

*Rule Utilitarianism:*

#+BEGIN_QUOTE
An act, X, is morally permissible if the consequences of following the
general rule, Y, of which act X is an instance, would bring about the
greatest good for the greatest number.
#+END_QUOTE

*Critic against Utilitarianism:*

1. Morality is basically tied to the production of happiness or pleasure.
2. Morality can ultimately be decided by consequences (of either acts
   or policies).

Critics of utilitarianism argue that morality can be grounded neither
in consequences

** Duty-based (Deontology)
Kant points out that, in some instances, performing our duties may
result in our being unhappy and may not necessarily lead to
consequences that are considered desirable.

Kant bases deontology on two premises:
1. Our nature as rational creatures
   - Rationality is what separates us from other kinds of creatures. If
     our primary nature were to merely seek happiness or pleasure, we
     would be indistinguishable from other creatures.
   - Rational nature reveals certain duties or obligations to each
     other as "rational beings"
2. Human beings are ends-in-themselves
   - A genuinely moral system would never permit some humans to be
     treated as means to the ends of others
   - We have a duty to treat fellow humans as ends; each individual
     has the same moral worth

*Categorical Imperative*:

#+BEGIN_QUOTE
Act always on that maxim or principle (or rule) that can be
universally binding, without exception, for all human beings.
#+END_QUOTE

This forms a system of universality and impartiality. The objective
rule to be followed—that is, the litmus test for determining when an
action will have moral worth—is whether the act complies with the
categorical imperative, and whether it is universal and impartial.

*Act Deontology*:

Ross argues that when two or more moral duties
clash, we have to look at individual situations in order to determine
which duty will override another.

Ross believes that we have certain prima facie (or self-evident)
duties, which, all things being equal, we must follow. He provides a
list of prima facie duties such as honesty, benevolence, justice, and
so forth.

1. Reflect on the competing prima facie duties. 
2. Weigh the evidence at hand to determine which course of action
   would be required in a particular circumstance.

** Contract-based
In his classic work /Leviathan/, Hobbes describes an original
"premoral" state that he calls the "state of nature." It is premoral
because there are no moral (or legal) rules yet in existence. In this
state, each individual is free to act in ways that satisfy his or her
own natural desires. According to Hobbes, our natural (or physical)
constitution is such that in the state of nature we act in ways that
will enable us to satisfy our desires (or appetites) and to avoid what
Hobbes calls our "aversions."

Hobbes believes that we are willing to surrender some of our
"absolute" freedoms to a sovereign. In return, we receive many
benefits, including a system of rules and laws that are designed and
enforced to protect individuals from being harmed by other members of
the system.

We see that it is in our individual self-interest to develop a moral
system with rules.

*** Criticisms
Some critics, such as Pojman (2006), point out that contract-based
theories provide the foundation for only a minimalist morality. They
are minimalist in the sense that we are obligated to behave morally
only where an explicit or formal contract exists. So if I have no
express contract with you, or if a country such as the United States
has no explicit contract with a developing nation, there is no moral
obligation for me to help you or for the United States to come to the
aid of that developing nation.

** Rights-Based
- humans possess some natural rights
- Two kinds of legal rights: positive rights and negative rights.
  Having a negative right to something simply means that one has the
  right not to be interfered with in carrying out the privileges
  associated with that right.
- Positive rights more rare and harder to justify.

** Character-based
Because virtue ethics focuses primarily on character development and
moral educa- tion, it does not need to rely on a system of formal
rules.

Character-based ethical systems would most likely flourish in cultures
where the emphasis placed on community life is stronger than that
accorded to the role of individuals themselves.

 | Type of Theory                  | Advantages                                         | Disadvantages                                                 |
 |---------------------------------+----------------------------------------------------+---------------------------------------------------------------|
 | Consequence-based (Utilitarian) | Stresses promotion of happiness and utility        | Ignores concerns of justice for the minority population       |
 | Duty-based (deontology)         | Stresses the role of duty and respect for persons  | Underestimates the importance of happiness and social utility |
 | Contract-based (rights)         | Provides a motivation for morality                 | Ofers only a minimal morality                                 |
 | Character-based (virtue)        | Stresses character development and moral education | Depends on homogeneous standards for morality                 |

** Moor's Just Consequentialist Framework
1. Deliberate over various policies from an impartial point of view to
   determine whether they meet the criteria for being ethical
   policies. A policy is ethical, if it
   - does not cause any unnecessary harms to individuals and groups,
     and
   - supports individual rights, the fulfilling of duties, etc.
2. Select the best policy from the set of just policies arrived at in
   the deliberation stage by ranking ethical policies in terms of
   benefits and (justifiable) harms. In doing this, be sure to:
   - weigh carefully between the good consequences and bad
     consequences in the ethical policies, and
   - distinguish between disagreements about facts and disagreements
     about principles and values, when deciding which particular
     ethical policy should be adopted. (Knowledge about the facts
     surrounding a particular case should inform the decision-making
     process.)

* Professional Ethics
Professionals are experts in a field, which provides them an advantage
over the lay person and that professional’s work has the potential to
impact—either positively or negatively—the general public at large.

Broadly speaking, a computer/IT professional is anyone employed in the
computing and IT fields—from software and hardware engineers, to
specialists such as support person- nel, network administrators, and
computer repair technicians.

As IT professionals we have significant opportunities to:

1. do good or cause harm,
2. enable others to do good or cause harm,
3. influence others to do good or cause harm.

- Moral Responsibility :: determined by looking at causality and
     intent. X is responsible for Y if X caused Y, regardless of
     intention of outcome, or regardless of the outcome of an
     intention.
- Legal Liability :: usually a legal concept, determines compensation
     for harmful consequences, rather than blame. May be legally
     liable, though not morally responsible
- Accountability :: Broader concept than liability that finds
                    answerable — to superiors, authorities, or public.
                    Helps because responsibility is hard to pinpoint
                    to individuals in large software developments.

** Whistleblowing
Morally permitted to blow the whistle:
1. The product will do "serious and considerable harm" to the public.
2. The engineer(s) have reported the "serious threat" to their
   immediate supervisor.
3. The engineer(s) have "exhausted the internal procedures and
   possibilities" within the company, including going to the board of
   directors, having received no support from their immediate
   supervisor.

To have a strict moral obligation to blow the whistle, De George
   believes that two additional conditions must be satisfied: 
1. The engineer(s) have "accessible, documented evidence that would
   convince a reasonable, impartial, observer that one’s view of the
   situation is correct."
2. The engineer(s) have "good reasons to believe that by going public
   the necessary changes will be brought about."

* Privacy
Consider the impact that changes involving this technology have had on
privacy with respect to the:

1. amount of personal information that can be collect,
2. speed at which personal information can be transmitted,
3. duration of time that the information can be retained,
4. kind of information that can be acquired and exchanged.

** Definitions
- Accessibility privacy :: Privacy is defined as one’s physically
     being let alone, or being free from intrusion into one’s physical
     space.
- Decisional privacy :: Privacy is defined as freedom from
     interference in one’s choices and decisions.
- Informational privacy :: Privacy is defined as control over the flow
     of one’s personal information, including the transfer and
     exchange of that information.

** Moor's Account of Privacy
#+BEGIN_QUOTE
An individual [has] privacy in a situation with regard to others if
and only if in that situation the individual [is] protected from
intrusion, interference, and information access by others.
#+END_QUOTE

*** Naturally private vs normatively private
In a naturally private situation, individuals are protected from
access and interference from others by natural means, for example,
physical boundaries such as those one enjoys while hiking alone in the
woods. In this case, privacy can be lost but not violated, because
there are no norms—conventional, legal, or ethical—according to which
one has a right, or even an expectation, to be protected. In a
normatively private situation, on the other hand, individuals are
protected by conventional norms (e.g., formal laws and informal
policies) because they involve certain kinds of zones or contexts that
we have determined to need normative protection.

** Contextual Integrity
Nissenbaum’s privacy framework requires that the processes used in
gathering and disseminating information (a) are "appropriate to a
particular context" and (b) comply with norms that govern the flow of
personal information in a given context. She refers to these two types
of informational norms as follows:

1. Norms of appropriateness.
2. Norms of distribution.

Whereas norms of appropriateness determine whether a given type of
personal information is either appropriate or inappropriate to divulge
within a particular context, norms of distribution restrict or limit
the flow of information within and across contexts. When either norm
has been "breached," a violation of privacy occurs; conversely, the
contextual integrity of the flow of personal information is maintained
when both kinds of norms are "respected."

** The Value of Privacy
Fried suggests that unlike most instrumental values that are simply
one means among others for achieving a desired end, privacy is also
essential, that is, necessary to achieve some important human ends,
such as trust and friendship. We tend to associate intrinsic values
with necessary conditions and instrumental values with contingent, or
nonnecessary conditions; so while privacy is instrumental in that it
is a means to certain human ends, Fried argues that it is also a
necessary condition for achieving those ends.

Moor believes that privacy is an articulation, or "expression" of the
"core value" security, which in turn is essential across cultures, for
human flourishing.

Based on the insights of DeCew and others, one might infer that
privacy is a value that simply benefits individuals. However, some
authors have pointed out the social value that privacy also provides,
noting that privacy is essential for democracy.

* Security
| Type    | What                                                                                     |
|---------+------------------------------------------------------------------------------------------|
| Data    | Securing data that resides in computer databases; transmitted between computer systems   |
| System  | Securing hardware and operating system resources; application software and programs      |
| Network | Securitng the infrastructure of privately owned networks; infrastructure of the Internet |

- Data security :: Concerned with vulnerabilities pertaining to
                   unauthorized access to data, as well as with
                   threats to the confidentiality, integrity, and
                   availability of data that resides in computer
                   storage devices or is exchanged between computer
                   systems.
- System security :: Concerned with attacks on system resources (such
     as computer hardware, operating system software, and application
     software) by malicious programs.
- Network security :: Concerned with attacks on computer networks,
     including the infrastructure of privately owned networks as well
     as the Internet itself.

** Cloud Computing
#+BEGIN_QUOTE
a model for enabling ubiquitous, convenient, on-demand network access
to a shared pool of configurable computing resources (e.g., networks,
servers, storage, applications and services).
#+END_QUOTE

*** Major Concerns
 1. How users can control their data stored in the cloud—currently,
    users have very little "control over or direct knowledge about how
    their information is transmitted, processed, or stored".
 2. Integrity of the data —- for example, if the host company goes out
    of business, what happens to the users’ data?
 3. Access to the data; i.e., can the host deny a user access to
    his/her own data?
 4. And a fourth concern has to do with who actually "owns" the data
    that is stored in the cloud

** Hacking and Hacker Ethic
According to Simpson (2006), a hacker is anyone who "accesses a
computer system or network without authorization from the owner."

Steven Levy (2001)
1. Access to computers should be unlimited and total.
2. All information should be free.
3. Mistrust authority–promote decentralization.
4. Hackers should be judged by their hacking (not by bogus criteria
   such as degrees, age, race, or position).
5. You can create art and beauty on a computer.
6. Computers can change your life for the better.

** Cyberterrorism
Dorothy Denning (2004) defines it as the “convergence of terrorism and
cyberspace.” As such, cyberterrorism covers politically motivated
hacking operations intended to cause grave harm—that is, resulting in
either loss of life or severe economic loss, or both.

** Hacktivism
"Electronic Civil Disobedience" (ECD). Criteria for CD:

1. No damage done to persons or property. (Debatable, depending on context)
2. Nonviolent.
3. Not for personal profit.
4. Ethical motivation—the strong conviction that a law is unjust, or
   unfair, to the extreme detriment of the common good.
5. Willingness to accept personal responsibility for the outcome of
   actions.

- Hacktivism :: The convergence of political activism and computer
                hacking techniques to engage in a new form of civil
                disobedience.
- Cyberterrorism :: The convergence of cybertechnology and terrorism
                    for carrying out acts of terror in (or via) cyberspace.
- Information Warfare :: Using malware in cyberattacks designed to
     mislead the enemy and disrupt/damage an opponent’s military
     defense system and its critical infrastructure.  

* Appendix
** ACM Code of Ethics
Software Engineering Code of Ethics and Professional Practice (Full Version)

PREAMBLE

omputers have a central and growing role in commerce, industry,
government, medicine, education, entertainment and society at large.
Software engineers are those who contribute by direct participation or
by teaching, to the analysis, specification, design, development,
certification, maintenance and testing of software systems. Because of
their roles in developing software systems, software engineers have
significant opportunities to do good or cause harm, to enable others
to do good or cause harm, or to influence others to do good or cause
harm. To ensure, as much as possible, that their efforts will be used
for good, software engineers must commit themselves to making software
engineering a beneficial and respected profession. In accordance with
that commitment, software engineers shall adhere to the following Code
of Ethics and Professional Practice.

The Code contains eight Principles related to the behavior of and
decisions made by professional software engineers, including
practitioners, educators, managers, supervisors and policy makers, as
well as trainees and students of the profession. The Principles
identify the ethically responsible relationships in which individuals,
groups, and organizations participate and the primary obligations
within these relationships. The Clauses of each Principle are
illustrations of some of the obligations included in these
relationships. These obligations are founded in the software
engineer’s humanity, in special care owed to people affected by the
work of software engineers, and the unique elements of the practice of
software engineering. The Code prescribes these as obligations of
anyone claiming to be or aspiring to be a software engineer.

It is not intended that the individual parts of the Code be used in
isolation to justify errors of omission or commission. The list of
Principles and Clauses is not exhaustive. The Clauses should not be
read as separating the acceptable from the unacceptable in
professional conduct in all practical situations. The Code is not a
simple ethical algorithm that generates ethical decisions. In some
situations standards may be in tension with each other or with
standards from other sources. These situations require the software
engineer to use ethical judgment to act in a manner which is most
consistent with the spirit of the Code of Ethics and Professional
Practice, given the circumstances.

Ethical tensions can best be addressed by thoughtful consideration of
fundamental principles, rather than blind reliance on detailed
regulations. These Principles should influence software engineers to
consider broadly who is affected by their work; to examine if they and
their colleagues are treating other human beings with due respect; to
consider how the public, if reasonably well informed, would view their
decisions; to analyze how the least empowered will be affected by
their decisions; and to consider whether their acts would be judged
worthy of the ideal professional working as a software engineer. In
all these judgments concern for the health, safety and welfare of the
public is primary; that is, the "Public Interest" is central to this
Code.

The dynamic and demanding context of software engineering requires a
code that is adaptable and relevant to new situations as they occur.
However, even in this generality, the Code provides support for
software engineers and managers of software engineers who need to take
positive action in a specific case by documenting the ethical stance
of the profession. The Code provides an ethical foundation to which
individuals within teams and the team as a whole can appeal. The Code
helps to define those actions that are ethically improper to request
of a software engineer or teams of software engineers.

The Code is not simply for adjudicating the nature of questionable
acts; it also has an important educational function. As this Code
expresses the consensus of the profession on ethical issues, it is a
means to educate both the public and aspiring professionals about the
ethical obligations of all software engineers. PRINCIPLES

Principle 1: PUBLIC

Software engineers shall act consistently with the public interest. In
particular, software engineers shall, as appropriate:

1.01. Accept full responsibility for their own work.

1.02. Moderate the interests of the software engineer, the employer,
the client and the users with the public good.

1.03. Approve software only if they have a well-founded belief that it
is safe, meets specifications, passes appropriate tests, and does not
diminish quality of life, diminish privacy or harm the environment.
The ultimate effect of the work should be to the public good.

1.04. Disclose to appropriate persons or authorities any actual or
potential danger to the user, the public, or the environment, that
they reasonably believe to be associated with software or related
documents.

1.05. Cooperate in efforts to address matters of grave public concern
caused by software, its installation, maintenance, support or
documentation.

1.06. Be fair and avoid deception in all statements, particularly
public ones, concerning software or related documents, methods and
tools.

1.07. Consider issues of physical disabilities, allocation of
resources, economic disadvantage and other factors that can diminish
access to the benefits of software.

1.08. Be encouraged to volunteer professional skills to good causes
and contribute to public education concerning the discipline.

Principle 2: CLIENT AND EMPLOYER

Software engineers shall act in a manner that is in the best interests
of their client and employer, consistent with the public interest. In
particular, software engineers shall, as appropriate:

2.01. Provide service in their areas of competence, being honest and
forthright about any limitations of their experience and education.

2.02. Not knowingly use software that is obtained or retained either
illegally or unethically.

2.03. Use the property of a client or employer only in ways properly
authorized, and with the client's or employer's knowledge and consent.

2.04. Ensure that any document upon which they rely has been approved,
when required, by someone authorized to approve it.

2.05. Keep private any confidential information gained in their
professional work, where such confidentiality is consistent with the
public interest and consistent with the law.

2.06. Identify, document, collect evidence and report to the client or
the employer promptly if, in their opinion, a project is likely to
fail, to prove too expensive, to violate intellectual property law, or
otherwise to be problematic.

2.07. Identify, document, and report significant issues of social
concern, of which they are aware, in software or related documents, to
the employer or the client.

2.08. Accept no outside work detrimental to the work they perform for
their primary employer.

2.09. Promote no interest adverse to their employer or client, unless
a higher ethical concern is being compromised; in that case, inform
the employer or another appropriate authority of the ethical concern.

Principle 3: PRODUCT

Software engineers shall ensure that their products and related
modifications meet the highest professional standards possible. In
particular, software engineers shall, as appropriate:

3.01. Strive for high quality, acceptable cost and a reasonable
schedule, ensuring significant tradeoffs are clear to and accepted by
the employer and the client, and are available for consideration by
the user and the public.

3.02. Ensure proper and achievable goals and objectives for any
project on which they work or propose.

3.03. Identify, define and address ethical, economic, cultural, legal
and environmental issues related to work projects.

3.04. Ensure that they are qualified for any project on which they
work or propose to work by an appropriate combination of education and
training, and experience.

3.05. Ensure an appropriate method is used for any project on which
they work or propose to work.

3.06. Work to follow professional standards, when available, that are
most appropriate for the task at hand, departing from these only when
ethically or technically justified.

3.07. Strive to fully understand the specifications for software on
which they work.

3.08. Ensure that specifications for software on which they work have
been well documented, satisfy the users’ requirements and have the
appropriate approvals.

3.09. Ensure realistic quantitative estimates of cost, scheduling,
personnel, quality and outcomes on any project on which they work or
propose to work and provide an uncertainty assessment of these
estimates.

3.10. Ensure adequate testing, debugging, and review of software and
related documents on which they work.

3.11. Ensure adequate documentation, including significant problems
discovered and solutions adopted, for any project on which they work.

3.12. Work to develop software and related documents that respect the
privacy of those who will be affected by that software.

3.13. Be careful to use only accurate data derived by ethical and
lawful means, and use it only in ways properly authorized.

3.14. Maintain the integrity of data, being sensitive to outdated or
flawed occurrences.

3.15 Treat all forms of software maintenance with the same
professionalism as new development.

Principle 4: JUDGMENT

Software engineers shall maintain integrity and independence in their
professional judgment. In particular, software engineers shall, as
appropriate:

4.01. Temper all technical judgments by the need to support and
maintain human values.

4.02 Only endorse documents either prepared under their supervision or
within their areas of competence and with which they are in agreement.

4.03. Maintain professional objectivity with respect to any software
or related documents they are asked to evaluate.

4.04. Not engage in deceptive financial practices such as bribery,
double billing, or other improper financial practices.

4.05. Disclose to all concerned parties those conflicts of interest
that cannot reasonably be avoided or escaped.

4.06. Refuse to participate, as members or advisors, in a private,
governmental or professional body concerned with software related
issues, in which they, their employers or their clients have
undisclosed potential conflicts of interest.

Principle 5: MANAGEMENT

Software engineering managers and leaders shall subscribe to and
promote an ethical approach to the management of software development
and maintenance . In particular, those managing or leading software
engineers shall, as appropriate:

5.01 Ensure good management for any project on which they work,
including effective procedures for promotion of quality and reduction
of risk.

5.02. Ensure that software engineers are informed of standards before
being held to them.

5.03. Ensure that software engineers know the employer's policies and
procedures for protecting passwords, files and information that is
confidential to the employer or confidential to others.

5.04. Assign work only after taking into account appropriate
contributions of education and experience tempered with a desire to
further that education and experience.

5.05. Ensure realistic quantitative estimates of cost, scheduling,
personnel, quality and outcomes on any project on which they work or
propose to work, and provide an uncertainty assessment of these
estimates.

5.06. Attract potential software engineers only by full and accurate
description of the conditions of employment.

5.07. Offer fair and just remuneration.

5.08. Not unjustly prevent someone from taking a position for which
that person is suitably qualified.

5.09. Ensure that there is a fair agreement concerning ownership of
any software, processes, research, writing, or other intellectual
property to which a software engineer has contributed.

5.10. Provide for due process in hearing charges of violation of an
employer's policy or of this Code.

5.11. Not ask a software engineer to do anything inconsistent with
this Code.

5.12. Not punish anyone for expressing ethical concerns about a
project.

Principle 6: PROFESSION

Software engineers shall advance the integrity and reputation of the
profession consistent with the public interest. In particular,
software engineers shall, as appropriate:

6.01. Help develop an organizational environment favorable to acting
ethically.

6.02. Promote public knowledge of software engineering.

6.03. Extend software engineering knowledge by appropriate
participation in professional organizations, meetings and
publications.

6.04. Support, as members of a profession, other software engineers
striving to follow this Code.

6.05. Not promote their own interest at the expense of the profession,
client or employer.

6.06. Obey all laws governing their work, unless, in exceptional
circumstances, such compliance is inconsistent with the public
interest.

6.07. Be accurate in stating the characteristics of software on which
they work, avoiding not only false claims but also claims that might
reasonably be supposed to be speculative, vacuous, deceptive,
misleading, or doubtful.

6.08. Take responsibility for detecting, correcting, and reporting
errors in software and associated documents on which they work.

6.09. Ensure that clients, employers, and supervisors know of the
software engineer's commitment to this Code of ethics, and the
subsequent ramifications of such commitment.

6.10. Avoid associations with businesses and organizations which are
in conflict with this code.

6.11. Recognize that violations of this Code are inconsistent with
being a professional software engineer.

6.12. Express concerns to the people involved when significant
violations of this Code are detected unless this is impossible,
counter-productive, or dangerous.

6.13. Report significant violations of this Code to appropriate
authorities when it is clear that consultation with people involved in
these significant violations is impossible, counter-productive or
dangerous.

Principle 7: COLLEAGUES

Software engineers shall be fair to and supportive of their
colleagues. In particular, software engineers shall, as appropriate:

7.01. Encourage colleagues to adhere to this Code.

7.02. Assist colleagues in professional development.

7.03. Credit fully the work of others and refrain from taking undue
credit.

7.04. Review the work of others in an objective, candid, and
properly-documented way.

7.05. Give a fair hearing to the opinions, concerns, or complaints of
a colleague.

7.06. Assist colleagues in being fully aware of current standard work
practices including policies and procedures for protecting passwords,
files and other confidential information, and security measures in
general.

7.07. Not unfairly intervene in the career of any colleague; however,
concern for the employer, the client or public interest may compel
software engineers, in good faith, to question the competence of a
colleague.

7.08. In situations outside of their own areas of competence, call
upon the opinions of other professionals who have competence in that
area.

Principle 8: SELF

Software engineers shall participate in lifelong learning regarding
the practice of their profession and shall promote an ethical approach
to the practice of the profession. In particular, software engineers
shall continually endeavor to:

8.01. Further their knowledge of developments in the analysis,
specification, design, development, maintenance and testing of
software and related documents, together with the management of the
development process.

8.02. Improve their ability to create safe, reliable, and useful
quality software at reasonable cost and within a reasonable time.

8.03. Improve their ability to produce accurate, informative, and
well-written documentation.

8.04. Improve their understanding of the software and related
documents on which they work and of the environment in which they will
be used.

8.05. Improve their knowledge of relevant standards and the law
governing the software and related documents on which they work.

8.06 Improve their knowledge of this Code, its interpretation, and its
application to their work.

8.07 Not give unfair treatment to anyone because of any irrelevant
prejudices.

8.08. Not influence others to undertake any action that involves a
breach of this Code.

8.09. Recognize that personal violations of this Code are inconsistent
with being a professional software engineer.
